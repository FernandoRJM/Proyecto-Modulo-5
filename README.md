# Detector de Noticias Falsas con Redes Neuronales (NLP)

## üìù Descripci√≥n
Este proyecto desarrolla un modelo de Deep Learning dise√±ado para clasificar noticias como "reales" o "falsas" (fake news). Utilizando t√©cnicas de Procesamiento de Lenguaje Natural (NLP) y redes neuronales secuenciales, el modelo analiza el contenido textual para identificar patrones de desinformaci√≥n, un problema cr√≠tico exacerbado desde la pandemia de COVID-19.

## üõ†Ô∏è Herramientas y Tecnolog√≠as
‚Ä¢ Lenguaje: Python 3.x. 
‚Ä¢ Librer√≠as principales: TensorFlow/Keras, Pandas, NumPy, Scikit-Learn, NLTK. 
‚Ä¢ T√©cnicas de NLP: * Tokenizaci√≥n y limpieza de texto (remoci√≥n de stopwords). * Secuenciaci√≥n y Padding de texto. * Capas de Embedding para representaci√≥n vectorial de palabras. ‚Ä¢ Arquitectura del Modelo: Red Neuronal Secuencial (Sequential) con capas densas y funciones de activaci√≥n personalizadas.

## üìä Dashboard / Resultados
El modelo de red neuronal secuencial fue dise√±ado y entrenado para la detecci√≥n de noticias falsas utilizando el dataset WELFake. Los resultados clave fueron:

1. Desempe√±o del Modelo

- Accuracy: El modelo alcanz√≥ una precisi√≥n del 94.5% en el conjunto de validaci√≥n tras el entrenamiento.
- Loss: Se logr√≥ reducir la p√©rdida hasta un valor de 0.12, lo que indica una alta capacidad de generalizaci√≥n del modelo frente a nuevos textos.
- Optimizaci√≥n de √âpocas: Se determin√≥ que 5 √©pocas de entrenamiento eran el punto √≥ptimo. M√°s all√° de esto, se observ√≥ el inicio de un ligero overfitting donde la precisi√≥n de entrenamiento segu√≠a subiendo pero la de validaci√≥n se estabilizaba.

2. Pruebas de Validaci√≥n Externa
El modelo fue sometido a pruebas con art√≠culos reales fuera del dataset original:

- Noticia Falsa (Breitbart): El modelo clasific√≥ correctamente el art√≠culo sobre James Comey como "FAKE" con un alto nivel de confianza.
- Noticia Verdadera (Washington Post): El modelo identific√≥ correctamente el art√≠culo sobre la √°rbitra Kathryn Nesbitt como "REAL".

3. Arquitectura y Preprocesamiento
Se implement√≥ una capa de Embedding para convertir las palabras en vectores densos, seguida de capas Flatten y Dense con activaci√≥n ReLU y Sigmoid.
El preprocesamiento incluy√≥ la eliminaci√≥n de stopwords y la tokenizaci√≥n de las 10,000 palabras m√°s frecuentes, asegurando que el modelo se centrara en el contenido sem√°ntico relevante.
